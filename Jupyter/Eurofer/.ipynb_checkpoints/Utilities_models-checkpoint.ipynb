{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c94a2-e6f8-4624-9780-cc9272e95408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from IPython.display import display, Markdown, Math, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "\n",
    "####################################################################################################\n",
    "# Define the general polynomial model of degree n, return sum(c * x**i for i, c in enumerate(coeffs))\n",
    "def polynomial_model(x, *params):\n",
    "    return sum([p * (x ** i) for i, p in enumerate(params)])\n",
    "\n",
    "###################################################################################################\n",
    "# Function to calculate and return goodness-of-fit parameters\n",
    "def fit_poly(x, y, degree):\n",
    "    # Perform curve fitting\n",
    "    initial_guess = np.ones(degree + 1)  # Initial guess for the coefficients\n",
    "    popt, _ = curve_fit(polynomial_model, x, y, p0=initial_guess)\n",
    "    \n",
    "    # Calculate the residuals\n",
    "    residuals = y - polynomial_model(x, *popt)\n",
    "\n",
    "    # Calculate the total sum of squares (TSS)\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "\n",
    "    # Calculate the residual sum of squares (RSS)\n",
    "    ss_res = np.sum(residuals ** 2)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    # Calculate the reduced chi-squared\n",
    "    # Degrees of freedom: number of observations - number of parameters\n",
    "    degrees_of_freedom = len(x) - len(popt)\n",
    "    reduced_chi_squared = ss_res / degrees_of_freedom\n",
    "\n",
    "    # Data to be written\n",
    "    fit_data = {\n",
    "        'Optimized parameters': popt,\n",
    "        \"R-squared\": r_squared,\n",
    "        \"Reduced chi-squared\": reduced_chi_squared\n",
    "    }\n",
    "\n",
    "    # Display the formatted output in the Jupyter Notebook cell\n",
    "    output = \"# Goodness-of-fit parameters\\n\"\n",
    "    for key, value in fit_data.items():\n",
    "        output += f'\\n{key}: {value}\\n'\n",
    "\n",
    "    return output, popt\n",
    "\n",
    "#################################################################################################\n",
    "# Function to format coefficients in scientific notation for LaTeX\n",
    "def format_coefficient(value):\n",
    "    sci = \"{:.5e}\".format(value).split('e')\n",
    "    base = sci[0]\n",
    "    exponent = int(sci[1])\n",
    "    sign = \"-\" if base.startswith('-') else \"+\"\n",
    "    base = base.lstrip('-')\n",
    "    return f\"{sign} {base} \\\\times 10^{{{exponent}}}\"\n",
    "\n",
    "##################################################################################################\n",
    "# Generalized function to display fitting parameters and LaTeX equation\n",
    "def display_fitting(material_name, property_name, output, popt):\n",
    "    # Print the output\n",
    "    display(HTML(\"<hr>\"))\n",
    "    text = f'**Fitting parameters for {material_name}** \\n'\n",
    "    display(Markdown(text))\n",
    "    print(output)\n",
    "\n",
    "    # Format the coefficients\n",
    "    formatted_coeffs = [format_coefficient(c) for c in popt]\n",
    "\n",
    "    # Handle T^0 term separately\n",
    "    equation_terms = [formatted_coeffs[0]]  # Start with the constant term\n",
    "\n",
    "    # Create the polynomial equation in LaTeX format for terms T^i where i > 0\n",
    "    for i in range(1, len(popt)):\n",
    "        term = formatted_coeffs[i]\n",
    "        if term.startswith('+'):\n",
    "            equation_terms.append(f\"{term} T^{i}\")\n",
    "        else:\n",
    "            equation_terms.append(f\"{term} T^{i}\")\n",
    "\n",
    "    # Join the terms without adding an extra plus sign at the beginning\n",
    "    equation = rf'{property_name} = ' + ' '.join(equation_terms).replace(' + -', ' -')\n",
    "\n",
    "    # Display the equation using LaTeX formatting with the formatted coefficients\n",
    "    print(f'The equation for {material_name} {property_name} is:\\n')\n",
    "    # display(Math(equation))\n",
    "     # Display the equation using LaTeX formatting with the formatted coefficients inside a box\n",
    "    boxed_equation = f\"\"\"\n",
    "    <div style=\"border: 2px solid black; padding: 10px; display: inline-block;\">\n",
    "        $$ {equation} $$\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(boxed_equation))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "#################################################################################################\n",
    "def fit_poly_with_confidence(x, y, degree, confidence=0.95):\n",
    "    # Perform curve fitting\n",
    "    initial_guess = np.ones(degree + 1)  # Initial guess for the coefficients\n",
    "    try:\n",
    "        popt, pcov = curve_fit(polynomial_model, x, y, p0=initial_guess)\n",
    "        \n",
    "        # Calculate the mean fit\n",
    "        mean_fit = polynomial_model(x, *popt)\n",
    "         \n",
    "        # Calculate the residuals\n",
    "        residuals = y - mean_fit\n",
    "    \n",
    "        # Calculate the total sum of squares (TSS)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "      \n",
    "        # Calculate the residual sum of squares (RSS)\n",
    "        ss_res = np.sum(residuals ** 2)\n",
    "      \n",
    "        # Calculate R-squared\n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "      \n",
    "        # Calculate the reduced chi-squared\n",
    "        # Degrees of freedom: number of observations - number of parameters\n",
    "        degrees_of_freedom = len(x) - len(popt)\n",
    "        reduced_chi_squared = ss_res / degrees_of_freedom\n",
    "       \n",
    "        # Calculate the 95% confidence intervals for the fit parameters\n",
    "        alpha = 1.0 - confidence\n",
    "        dof = max(0, degrees_of_freedom)\n",
    "        t_val = t.ppf(1.0 - alpha / 2., dof)\n",
    "        ci = t_val * np.sqrt(np.diag(pcov))\n",
    "      \n",
    "        # Calculate the prediction intervals\n",
    "        sum_squared_errors = np.sum(residuals**2)\n",
    "        mean_x = np.mean(x)\n",
    "        n = len(x)\n",
    "        t_val = t.ppf((1.0 + confidence) / 2.0, dof)\n",
    "        \n",
    "        pred_interval = []\n",
    "        for i in range(len(x)):\n",
    "            s_err = np.sqrt(1/n + (x[i] - mean_x)**2 / np.sum((x - mean_x)**2))\n",
    "            margin = t_val * np.sqrt(sum_squared_errors / dof) * s_err\n",
    "            pred_interval.append(margin)\n",
    "\n",
    "        pred_interval = np.array(pred_interval)\n",
    "        lower_pred = mean_fit - pred_interval\n",
    "        upper_pred = mean_fit + pred_interval\n",
    "\n",
    "        # Data to be written\n",
    "        fit_data = {\n",
    "            'Optimized parameters': popt,\n",
    "            \"R-squared\": r_squared,\n",
    "            \"Reduced chi-squared\": reduced_chi_squared,\n",
    "            \"Confidence intervals\": ci,\n",
    "            \"Mean fit\": mean_fit,\n",
    "            \"Lower 95% prediction\": lower_pred,\n",
    "            \"Upper 95% prediction\": upper_pred\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred:\", e)\n",
    "        fit_data = {\n",
    "            'Optimized parameters': None,\n",
    "            \"R-squared\": None,\n",
    "            \"Reduced chi-squared\": None,\n",
    "            \"Confidence intervals\": None,\n",
    "            \"Mean fit\": None,\n",
    "            \"Lower 95% prediction\": None,\n",
    "            \"Upper 95% prediction\": None,\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "    return fit_data\n",
    "\n",
    "##################################################################################################\n",
    "# Weibull distribution model function\n",
    "# When x<Œº:the function is zero because the distribution starts at  ùúá\n",
    "# This is a key characteristic, as the Weibull distribution is defined only for x‚â•Œº.\n",
    "# For x‚â•Œº: The distribution takes on different shapes depending on the value of :\n",
    "# Œ≥<1: The hazard function is decreasing, indicating a higher probability of failure (or event) early on, with the rate decreasing over time.\n",
    "# The PDF has a peak at  x=Œº and decreases monotonically.\n",
    "# Œ≥=1: The distribution simplifies to an exponential distribution with a constant hazard function.\n",
    "# The PDF is a decreasing exponential function.\n",
    "# Œ≥>1: The hazard function is increasing, indicating a lower probability of failure early on, with the rate increasing over time.\n",
    "# The PDF initially increases, reaches a peak, and then decreases, showing a typical \"bell\" shape.\n",
    "# Impact of Œ±:\n",
    "# Larger values of Œ± stretch the distribution, making it wider and less peaked.\n",
    "# Smaller values of Œ± compress the distribution, making it narrower and more peaked.\n",
    "# Impact of Œº:\n",
    "# The location parameter Œº shifts the entire distribution along the x-axis.\n",
    "# Changing Œº does not affect the shape of the distribution but changes the starting point.\n",
    "\n",
    "\n",
    "\n",
    "def weibull_model(x, gamma, alpha, mu):\n",
    "    return (gamma / alpha) * ((x - mu) / alpha)**(gamma - 1) * np.exp(-((x - mu) / alpha)**gamma)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Function to calculate and return goodness-of-fit parameters for Weibull model with confidence intervals\n",
    "def fit_weibull_with_confidence(x, y, initial_guess, confidence=0.95):\n",
    "    # Initial guess for parameters: gamma, alpha, mu\n",
    "    \n",
    "    try:\n",
    "        # Perform curve fitting\n",
    "        popt, pcov = curve_fit(weibull_model, x, y, p0=initial_guess)\n",
    "        \n",
    "        # Calculate the mean fit\n",
    "        mean_fit = weibull_model(x, *popt)\n",
    "        \n",
    "        # Calculate the residuals\n",
    "        residuals = y - mean_fit\n",
    "    \n",
    "        # Calculate the total sum of squares (TSS)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "      \n",
    "        # Calculate the residual sum of squares (RSS)\n",
    "        ss_res = np.sum(residuals ** 2)\n",
    "      \n",
    "        # Calculate R-squared\n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "      \n",
    "        # Calculate the reduced chi-squared\n",
    "        # Degrees of freedom: number of observations - number of parameters\n",
    "        degrees_of_freedom = len(x) - len(popt)\n",
    "        reduced_chi_squared = ss_res / degrees_of_freedom\n",
    "       \n",
    "        # Calculate the confidence intervals for the fit parameters\n",
    "        alpha = 1.0 - confidence\n",
    "        dof = max(0, degrees_of_freedom)\n",
    "        t_val = t.ppf(1.0 - alpha / 2., dof)\n",
    "        ci = t_val * np.sqrt(np.diag(pcov))\n",
    "      \n",
    "        # Calculate the prediction intervals\n",
    "        sum_squared_errors = np.sum(residuals**2)\n",
    "        mean_x = np.mean(x)\n",
    "        n = len(x)\n",
    "        t_val = t.ppf((1.0 + confidence) / 2.0, dof)\n",
    "        \n",
    "        pred_interval = []\n",
    "        for i in range(len(x)):\n",
    "            s_err = np.sqrt(1/n + (x[i] - mean_x)**2 / np.sum((x - mean_x)**2))\n",
    "            margin = t_val * np.sqrt(sum_squared_errors / dof) * s_err\n",
    "            pred_interval.append(margin)\n",
    "\n",
    "        pred_interval = np.array(pred_interval)\n",
    "        lower_pred = mean_fit - pred_interval\n",
    "        upper_pred = mean_fit + pred_interval\n",
    "\n",
    "        # Data to be written\n",
    "        fit_data = {\n",
    "            'Optimized parameters (gamma, alpha, mu)': popt,\n",
    "            \"R-squared\": r_squared,\n",
    "            \"Reduced chi-squared\": reduced_chi_squared,\n",
    "            \"Confidence intervals\": ci,\n",
    "            \"Mean fit\": mean_fit,\n",
    "            \"Lower 95% prediction\": lower_pred,\n",
    "            \"Upper 95% prediction\": upper_pred\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred:\", e)\n",
    "        fit_data = {\n",
    "            'Optimized parameters': None,\n",
    "            \"R-squared\": None,\n",
    "            \"Reduced chi-squared\": None,\n",
    "            \"Confidence intervals\": None,\n",
    "            \"Mean fit\": None,\n",
    "            \"Lower 95% prediction\": None,\n",
    "            \"Upper 95% prediction\": None,\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "    return fit_data\n",
    "###################################################################################################\n",
    "# Generalized Exponential model function\n",
    "# Constant Term (a): This term shifts the entire function vertically. \n",
    "# It determines the baseline value of the function when all other terms are zero.\n",
    "# Linear Term (ùëè+ùëêùë•): introduces a linear component that depends on  ùë•\n",
    "# b is the y-intercept of this linear component.\n",
    "# c is the slope of the linear component, determining how quickly the value of \n",
    "# b+cx changes with ùë•\n",
    "# Exponential Term (exp(dx)): It controls the rate of exponential growth or decay:\n",
    "# If ùëë>0 , the function grows exponentially.\n",
    "# If ùëë<0, the function decays exponentially.\n",
    "\n",
    "\n",
    "def exponential_model(x, a, b, c, d):\n",
    "    return a + (b + c * x) * np.exp(d * x)\n",
    "\n",
    "# Function to calculate and return goodness-of-fit parameters for exponential model with confidence intervals\n",
    "def fit_exponential_with_confidence(x, y, initial_guess, confidence=0.95):\n",
    "    try:\n",
    "        # Perform curve fitting\n",
    "        popt, pcov = curve_fit(exponential_model, x, y, p0=initial_guess)\n",
    "        \n",
    "        # Calculate the mean fit\n",
    "        mean_fit = exponential_model(x, *popt)\n",
    "        \n",
    "        # Calculate the residuals\n",
    "        residuals = y - mean_fit\n",
    "    \n",
    "        # Calculate the total sum of squares (TSS)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "      \n",
    "        # Calculate the residual sum of squares (RSS)\n",
    "        ss_res = np.sum(residuals ** 2)\n",
    "      \n",
    "        # Calculate R-squared\n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "      \n",
    "        # Calculate the reduced chi-squared\n",
    "        # Degrees of freedom: number of observations - number of parameters\n",
    "        degrees_of_freedom = len(x) - len(popt)\n",
    "        reduced_chi_squared = ss_res / degrees_of_freedom\n",
    "       \n",
    "        # Calculate the confidence intervals for the fit parameters\n",
    "        alpha = 1.0 - confidence\n",
    "        dof = max(0, degrees_of_freedom)\n",
    "        t_val = t.ppf(1.0 - alpha / 2., dof)\n",
    "        ci = t_val * np.sqrt(np.diag(pcov))\n",
    "      \n",
    "        # Calculate the prediction intervals\n",
    "        sum_squared_errors = np.sum(residuals**2)\n",
    "        mean_x = np.mean(x)\n",
    "        n = len(x)\n",
    "        t_val = t.ppf((1.0 + confidence) / 2.0, dof)\n",
    "        \n",
    "        pred_interval = []\n",
    "        for i in range(len(x)):\n",
    "            s_err = np.sqrt(1/n + (x[i] - mean_x)**2 / np.sum((x - mean_x)**2))\n",
    "            margin = t_val * np.sqrt(sum_squared_errors / dof) * s_err\n",
    "            pred_interval.append(margin)\n",
    "\n",
    "        pred_interval = np.array(pred_interval)\n",
    "        lower_pred = mean_fit - pred_interval\n",
    "        upper_pred = mean_fit + pred_interval\n",
    "\n",
    "        # Data to be written\n",
    "        fit_data = {\n",
    "            'Optimized parameters (a, b, c, d)': popt,\n",
    "            \"R-squared\": r_squared,\n",
    "            \"Reduced chi-squared\": reduced_chi_squared,\n",
    "            \"Confidence intervals\": ci,\n",
    "            \"Mean fit\": mean_fit,\n",
    "            \"Lower 95% prediction\": lower_pred,\n",
    "            \"Upper 95% prediction\": upper_pred\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred:\", e)\n",
    "        fit_data = {\n",
    "            'Optimized parameters': None,\n",
    "            \"R-squared\": None,\n",
    "            \"Reduced chi-squared\": None,\n",
    "            \"Confidence intervals\": None,\n",
    "            \"Mean fit\": None,\n",
    "            \"Lower 95% prediction\": None,\n",
    "            \"Upper 95% prediction\": None,\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "    return fit_data\n",
    "\n",
    "###################################################################################################\n",
    "# Transition function\n",
    "#  The function starts near ùëé for large negative ùë•. It transitions smoothly around ùë•=ùëë, \n",
    "# controlled by the parameter ùëí. It ends up behaving like ùëè+ùëêùë• for large positive ùë•\n",
    "# a: Shifts the entire function vertically.\n",
    "# b: Controls the final value for large positive x\n",
    "# c: Controls the slope of the linear component added to  ùëè\n",
    "# d: Controls the center of the transition.\n",
    "# e: Controls the steepness of the transition\n",
    "\n",
    "def transition_function(x, a, b, c, d, e):\n",
    "    return a + 0.5 * (b - a + c * x) * (1 + np.tanh((x - d) / e))\n",
    "\n",
    "# Function to calculate and return goodness-of-fit parameters with confidence intervals\n",
    "def fit_transition_with_confidence(x, y, initial_guess, confidence=0.95):\n",
    "    try:\n",
    "        # Perform curve fitting\n",
    "        popt, pcov = curve_fit(transition_function, x, y, p0=initial_guess)\n",
    "        \n",
    "        # Calculate the mean fit\n",
    "        mean_fit = transition_function(x, *popt)\n",
    "        \n",
    "        # Calculate the residuals\n",
    "        residuals = y - mean_fit\n",
    "    \n",
    "        # Calculate the total sum of squares (TSS)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "      \n",
    "        # Calculate the residual sum of squares (RSS)\n",
    "        ss_res = np.sum(residuals ** 2)\n",
    "      \n",
    "        # Calculate R-squared\n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "      \n",
    "        # Calculate the reduced chi-squared\n",
    "        # Degrees of freedom: number of observations - number of parameters\n",
    "        degrees_of_freedom = len(x) - len(popt)\n",
    "        reduced_chi_squared = ss_res / degrees_of_freedom\n",
    "       \n",
    "        # Calculate the confidence intervals for the fit parameters\n",
    "        alpha = 1.0 - confidence\n",
    "        dof = max(0, degrees_of_freedom)\n",
    "        t_val = t.ppf(1.0 - alpha / 2., dof)\n",
    "        ci = t_val * np.sqrt(np.diag(pcov))\n",
    "      \n",
    "        # Calculate the prediction intervals\n",
    "        sum_squared_errors = np.sum(residuals**2)\n",
    "        mean_x = np.mean(x)\n",
    "        n = len(x)\n",
    "        t_val = t.ppf((1.0 + confidence) / 2.0, dof)\n",
    "        \n",
    "        pred_interval = []\n",
    "        for i in range(len(x)):\n",
    "            s_err = np.sqrt(1/n + (x[i] - mean_x)**2 / np.sum((x - mean_x)**2))\n",
    "            margin = t_val * np.sqrt(sum_squared_errors / dof) * s_err\n",
    "            pred_interval.append(margin)\n",
    "\n",
    "        pred_interval = np.array(pred_interval)\n",
    "        lower_pred = mean_fit - pred_interval\n",
    "        upper_pred = mean_fit + pred_interval\n",
    "\n",
    "        # Data to be written\n",
    "        fit_data = {\n",
    "            'Optimized parameters (a, b, c, d, e)': popt,\n",
    "            \"R-squared\": r_squared,\n",
    "            \"Reduced chi-squared\": reduced_chi_squared,\n",
    "            \"Confidence intervals\": ci,\n",
    "            \"Mean fit\": mean_fit,\n",
    "            \"Lower 95% prediction\": lower_pred,\n",
    "            \"Upper 95% prediction\": upper_pred\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred:\", e)\n",
    "        fit_data = {\n",
    "            'Optimized parameters': None,\n",
    "            \"R-squared\": None,\n",
    "            \"Reduced chi-squared\": None,\n",
    "            \"Confidence intervals\": None,\n",
    "            \"Mean fit\": None,\n",
    "            \"Lower 95% prediction\": None,\n",
    "            \"Upper 95% prediction\": None,\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n",
    "    return fit_data\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
